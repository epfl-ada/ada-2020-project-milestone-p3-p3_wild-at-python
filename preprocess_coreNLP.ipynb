{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This code was run on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9mbcIfgpKxB-"
   },
   "outputs": [],
   "source": [
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SlwqxUMLHLb",
    "outputId": "68553d03-2a8f-47a9-f49e-edae7658598c"
   },
   "outputs": [],
   "source": [
    "#installing tweet-preprocessor used to preprocess the news\n",
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FTFHxthuKxCD"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import re, string, unicodedata\n",
    "import preprocessor as p\n",
    "import spacy, nltk, gensim, sklearn\n",
    "from gensim.parsing.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWXep7cWU8JP"
   },
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWkAEnVBVN3d"
   },
   "source": [
    "The datasets can be found in: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IFcbgHpUKxCE"
   },
   "outputs": [],
   "source": [
    "#set the data folder name\n",
    "DATA_FOLDER = 'data_news'\n",
    "\n",
    "#set the features data folder name \n",
    "FEATURES_FOLDER = 'news_features'\n",
    "\n",
    "#set the path for the news datasets using os.path.join to gurantee that it work on the different operating systems\n",
    "FAKE_DATASET= os.path.join(DATA_FOLDER, \"Fake.csv\")\n",
    "TRUE_DATASET= os.path.join(DATA_FOLDER, \"True.csv\")\n",
    "    \n",
    "#load the news datasets \n",
    "df_Fake = pd.read_csv(FAKE_DATASET )\n",
    "df_True = pd.read_csv(TRUE_DATASET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "VLGpAV4jKxCE",
    "outputId": "d250584d-18eb-439e-869b-883806a111d8"
   },
   "outputs": [],
   "source": [
    "df_Fake.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "nDB9USdRKxCF",
    "outputId": "a82fd280-e75f-431e-e57a-e2856ff90ce0"
   },
   "outputs": [],
   "source": [
    "df_True.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0fTeQGCKxCG",
    "outputId": "f44b1126-6695-41b6-8199-42839d1c54bf"
   },
   "outputs": [],
   "source": [
    "print(\"shape of Fake news dataset:\" , df_Fake.shape , \"\\nshape of True news dataset:\" , df_True.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A-8kqERVAqQ"
   },
   "source": [
    "We will only use the 'text' columns of our datasets to perform our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKmpga0dKxCH"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFCqOSwMVmFf"
   },
   "source": [
    "The news datasets requires some preprocessing before the analysis. In fact, the news contain a lot of links, tags ... that are useless for the linguistic cues analysis thus we delete them. We also map all the news to lower case letters to avoid miss-leading the models. We also perform some specific modifications to remove empty strings, multiple spaces... to ensure that we have proper entries both for the analysis and the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaWhinumKxCI"
   },
   "source": [
    "#### Fake text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MCW0pXJcKxCI"
   },
   "outputs": [],
   "source": [
    "#get the texts of Fake news\n",
    "df_Fake_text= df_Fake[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "XPSvc75XKxCI",
    "outputId": "5c7dbadc-9034-4046-f538-2956dbfcb91c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pope Francis used his annual Christmas Day message to rebuke Donald Trump without even mentioning his name. The Pope delivered his message just days after members of the United Nations condemned Trump s move to recognize Jerusalem as the capital of Israel. The Pontiff prayed on Monday for the  peaceful coexistence of two states within mutually agreed and internationally recognized borders. We see Jesus in the children of the Middle East who continue to suffer because of growing tensions between Israelis and Palestinians,  Francis said.  On this festive day, let us ask the Lord for peace for Jerusalem and for all the Holy Land. Let us pray that the will to resume dialogue may prevail between the parties and that a negotiated solution can finally be reached. The Pope went on to plead for acceptance of refugees who have been forced from their homes, and that is an issue Trump continues to fight against. Francis used Jesus for which there was  no place in the inn  as an analogy. Today, as the winds of war are blowing in our world and an outdated model of development continues to produce human, societal and environmental decline, Christmas invites us to focus on the sign of the Child and to recognize him in the faces of little children, especially those for whom, like Jesus,  there is no place in the inn,  he said. Jesus knows well the pain of not being welcomed and how hard it is not to have a place to lay one s head,  he added.  May our hearts not be closed as they were in the homes of Bethlehem. The Pope said that Mary and Joseph were immigrants who struggled to find a safe place to stay in Bethlehem. They had to leave their people, their home, and their land,  Francis said.  This was no comfortable or easy journey for a young couple about to have a child.   At heart, they were full of hope and expectation because of the child about to be born; yet their steps were weighed down by the uncertainties and dangers that attend those who have to leave their home behind. So many other footsteps are hidden in the footsteps of Joseph and Mary,  Francis said Sunday. We see the tracks of entire families forced to set out in our own day. We see the tracks of millions of persons who do not choose to go away, but driven from their land, leave behind their dear ones. Amen to that.Photo by Christopher Furlong/Getty Images.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Fake_text['text'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feBag77UKxCI"
   },
   "outputs": [],
   "source": [
    "#removal of URLs, Mentions\n",
    "df_Fake_text['text']= df_Fake_text['text'].apply(p.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "2SZRgmWGKxCI",
    "outputId": "e1566216-0666-46ba-c72a-53c8c558de1e"
   },
   "outputs": [],
   "source": [
    "df_Fake_text['text'].iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4lSvhjPKxCJ"
   },
   "outputs": [],
   "source": [
    "#first we separate words that are connected with '-' '/' '_'\n",
    "#Then we keep only alphabet caracters and some punctuation marks that are useful to detect sentences\n",
    "df_Fake_text['text']=df_Fake_text['text'].apply( lambda x: \"\".join(re.findall(r'[a-zA-Z]*[ ?.!,]', x.translate(str.maketrans({'-': ' ', '/': ' ', '_': ' '}))+' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bi5nPHIiKxCJ"
   },
   "outputs": [],
   "source": [
    "#map all characters to lowercase to make the text uniform\n",
    "#replace some sepcial cases to remove empty sentences\n",
    "df_Fake_text['text']= df_Fake_text['text'].apply(lambda x: x[:-1].lower().replace(\"...\", \"\").replace(\", ,\", \",\").replace(\". .\", \".\").replace(' ,', ',').replace(' .', '.').replace('  ',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "HAHgGIhsKxCJ",
    "outputId": "d40b4fb7-db8a-40fc-def8-02c7ea2a67e4"
   },
   "outputs": [],
   "source": [
    "#here we can see how an entry became after preprocessing \n",
    "df_Fake_text['text'].iloc[888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "JCw3Cf3FKxCJ",
    "outputId": "2531f17d-ee45-43be-90ab-c9a30151cace"
   },
   "outputs": [],
   "source": [
    "#This is how the entry was before preprocessing\n",
    "df_Fake['text'].iloc[888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_EJK37pKxCK"
   },
   "outputs": [],
   "source": [
    "#some news containes only links or tags thus after preprocessing they became empty text. We remove those because they are irrelevant for our analysis\n",
    "df_Fake_text= df_True_text[ ~df_Fake_text['text'].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRH9ankCX6K_"
   },
   "outputs": [],
   "source": [
    "print(\"shape of the Fake news dataframe after preprocessing: \", df_Fake_text.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwgi7tjnNZIU"
   },
   "outputs": [],
   "source": [
    "#save the new dataframe\n",
    "df_Fake_text.to_csv(os.path.join(FEATURES_FOLDER,\"df_Fake_text.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVr_wH6bKxCL"
   },
   "source": [
    "#### True Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iEWl7g7wKxCM",
    "outputId": "b0265886-b6de-4b7b-b37f-364a0b77ba3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we can see, all entries in the True news start with the company's name(Reuters) and locaion of news \n",
    "df_True['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "viydLWWBKxCM"
   },
   "outputs": [],
   "source": [
    "#get the texts of True news\n",
    "df_True_text= df_True[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lAqbWALWKxCM"
   },
   "outputs": [],
   "source": [
    "#We remove the first part of each news ( the origin part ) to avoid having bias\n",
    "df_True_text['text'] = df_True_text['text'].apply(lambda x : x.split('-', maxsplit=1)[1] if '-' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "D0dmqc2_KxCM",
    "outputId": "364d2dd1-6880-45a0-b54b-f58ba45b8866"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The head of a conservative Republican faction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transgender people will be allowed for the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The special counsel investigation of links be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump campaign adviser George Papadopoulos to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>President Donald Trump called on the U.S. Pos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0   The head of a conservative Republican faction...\n",
       "1   Transgender people will be allowed for the fi...\n",
       "2   The special counsel investigation of links be...\n",
       "3   Trump campaign adviser George Papadopoulos to...\n",
       "4   President Donald Trump called on the U.S. Pos..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_True_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Gbsk5wKuKxCM"
   },
   "outputs": [],
   "source": [
    "#removal of URLs, Mentions\n",
    "df_True_text['text']= df_True_text['text'].apply(p.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Z09nU3tfKxCM",
    "outputId": "9283cd7d-b99f-4e45-c43d-c3b19f7f5693"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a fiscal conservative on Sunday and urged budget restraint in . In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS Face the Nation, drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense discretionary spending on programs that support education, scientific research, infrastructure, public health and environmental protection. The (Trump) administration has already been willing to say: Were going to increase non-defense discretionary spending ... by about percent, Meadows, chairman of the small but influential House Freedom Caucus, said on the program. Now, Democrats are saying thats not enough, we need to give the government a pay raise of to percent. For a fiscal conservative, I dont see where the rationale is. ... Eventually you run out of other peoples money, he said. Meadows was among Republicans who voted in late December for their partys debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over years to the $20 trillion national debt. Its interesting to hear Mark talk about fiscal responsibility, Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. This is one of the least ... fiscally responsible bills weve ever seen passed in the history of the House of Representatives. I think were going to be paying for this for many, many years to come, Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than years, will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or entitlement reform, as the party often calls it, would be a top Republican priority in . In Republican parlance, entitlement programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryans early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the Dreamers, people brought illegally to the country as children. Trump in September put a March expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. We need to do DACA clean, she said. On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. and , the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_True_text['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pAShbBRfKxCN"
   },
   "outputs": [],
   "source": [
    "#we separate words that are connected with '-' '/' '_'\n",
    "#Then we keep only alphabet caracters and some punctuation marks that are useful to detect sentences\n",
    "df_True_text['text']=df_True_text['text'].apply( lambda x: \"\".join(re.findall(r'[a-zA-Z]*[ ?.!,]', x.translate(str.maketrans({'-': ' ', '/': ' ', '_': ' '}))+' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZT6Ry6-RKxCN"
   },
   "outputs": [],
   "source": [
    "#map all characters to lowercase to make the text uniform\n",
    "#replace some sepcial cases to remove empty sentences\n",
    "df_True_text['text']= df_True_text['text'].apply(lambda x: x[:-1].lower().replace(\"...\", \"\").replace(\", ,\", \",\").replace(\". .\", \".\").replace(' ,', ',').replace(' .', '.').replace('  ',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "u7YCw5Y4KxCN",
    "outputId": "e5cf86a4-4e1b-45c1-9107-e5f627e31b41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transgender people will be allowed for the first time to enlist in the u.s. military starting on monday as ordered by federal courts, the pentagon said on friday, after president donald trumps administration decided not to appeal rulings that blocked his transgender ban. two federal appeals courts, one in washington and one in virginia, last week rejected the administrations request to put on hold orders by lower court judges requiring the military to begin accepting transgender recruits on jan. a justice department official said the administration will not challenge those rulings. the department of defense has announced that it will be releasing an independent study of these issues in the coming weeks. so rather than litigate this interim appeal before that occurs, the administration has decided to wait for dods study and will continue to defend the presidents lawful authority in district court in the meantime, the official said, speaking on condition of anonymity. in september, the pentagon said it had created a panel of senior officials to study how to implement a directive by trump to prohibit transgender individuals from serving. the defense department has until feb. to submit a plan to trump. lawyers representing currently serving transgender service members and aspiring recruits said they had expected the administration to appeal the rulings to the conservative majority supreme court, but were hoping that would not happen. pentagon spokeswoman heather babb said in a as mandated by court order, the department of defense is prepared to begin accessing transgender applicants for military service jan. all applicants must meet all accession standards. jennifer levi, a lawyer with gay, lesbian and transgender advocacy group glad, called the decision not to appeal great news. im hoping it means the government has come to see that there is no way to justify a ban and that its not good for the military or our country, levi said. both glad and the american civil liberties union represent plaintiffs in the lawsuits filed against the administration. in a move that appealed to his hard line conservative supporters, trump announced in july that he would prohibit transgender people from serving in the military, reversing democratic president barack obamas policy of accepting them. trump said on twitter at the time that the military cannot be burdened with the tremendous medical costs and disruption that transgender in the military would entail. four federal judges  in baltimore, washington, d.c., seattle and riverside, california  have issued rulings blocking trumps ban while legal challenges to the republican presidents policy proceed. the judges said the ban would likely violate the right under the u.s. constitution to equal protection under the law. the pentagon on dec. issued guidelines to recruitment personnel in order to enlist transgender applicants by jan. the memo outlined medical requirements and specified how the applicants sex would be identified and even which undergarments they would wear. the trump administration previously said in legal papers that the armed forces were not prepared to train thousands of personnel on the medical standards needed to process transgender applicants and might have to accept some individuals who are not medically fit for service. the obama administration had set a deadline of july, to begin accepting transgender recruits. but trumps defense secretary, james mattis, postponed that date to jan., which the presidents ban then put off indefinitely. trump has taken other steps aimed at rolling back transgender rights. in october, his administration said a federal law banning gender based workplace discrimination does not protect transgender employees, reversing another obama era position. in february, trump rescinded guidance issued by the obama administration saying that public schools should allow transgender students to use the restroom that corresponds to their gender identity.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we can see how an entry became after preprocessing \n",
    "df_True_text['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Z_KOsX9hKxCN",
    "outputId": "3c970629-e478-4096-c7cd-70f21ab21545"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON (Reuters) - Transgender people will be allowed for the first time to enlist in the U.S. military starting on Monday as ordered by federal courts, the Pentagon said on Friday, after President Donald Trump’s administration decided not to appeal rulings that blocked his transgender ban. Two federal appeals courts, one in Washington and one in Virginia, last week rejected the administration’s request to put on hold orders by lower court judges requiring the military to begin accepting transgender recruits on Jan. 1. A Justice Department official said the administration will not challenge those rulings. “The Department of Defense has announced that it will be releasing an independent study of these issues in the coming weeks. So rather than litigate this interim appeal before that occurs, the administration has decided to wait for DOD’s study and will continue to defend the president’s lawful authority in District Court in the meantime,” the official said, speaking on condition of anonymity. In September, the Pentagon said it had created a panel of senior officials to study how to implement a directive by Trump to prohibit transgender individuals from serving. The Defense Department has until Feb. 21 to submit a plan to Trump. Lawyers representing currently-serving transgender service members and aspiring recruits said they had expected the administration to appeal the rulings to the conservative-majority Supreme Court, but were hoping that would not happen. Pentagon spokeswoman Heather Babb said in a statement: “As mandated by court order, the Department of Defense is prepared to begin accessing transgender applicants for military service Jan. 1. All applicants must meet all accession standards.” Jennifer Levi, a lawyer with gay, lesbian and transgender advocacy group GLAD, called the decision not to appeal “great news.” “I’m hoping it means the government has come to see that there is no way to justify a ban and that it’s not good for the military or our country,” Levi said. Both GLAD and the American Civil Liberties Union represent plaintiffs in the lawsuits filed against the administration. In a move that appealed to his hard-line conservative supporters, Trump announced in July that he would prohibit transgender people from serving in the military, reversing Democratic President Barack Obama’s policy of accepting them. Trump said on Twitter at the time that the military “cannot be burdened with the tremendous medical costs and disruption that transgender in the military would entail.” Four federal judges - in Baltimore, Washington, D.C., Seattle and Riverside, California - have issued rulings blocking Trump’s ban while legal challenges to the Republican president’s policy proceed. The judges said the ban would likely violate the right under the U.S. Constitution to equal protection under the law. The Pentagon on Dec. 8 issued guidelines to recruitment personnel in order to enlist transgender applicants by Jan. 1. The memo outlined medical requirements and specified how the applicants’ sex would be identified and even which undergarments they would wear. The Trump administration previously said in legal papers that the armed forces were not prepared to train thousands of personnel on the medical standards needed to process transgender applicants and might have to accept “some individuals who are not medically fit for service.” The Obama administration had set a deadline of July 1, 2017, to begin accepting transgender recruits. But Trump’s defense secretary, James Mattis, postponed that date to Jan. 1, 2018, which the president’s ban then put off indefinitely. Trump has taken other steps aimed at rolling back transgender rights. In October, his administration said a federal law banning gender-based workplace discrimination does not protect transgender employees, reversing another Obama-era position. In February, Trump rescinded guidance issued by the Obama administration saying that public schools should allow transgender students to use the restroom that corresponds to their gender identity. '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is how the entry was before preprocessing\n",
    "df_True['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNsc7-KYKxCN"
   },
   "outputs": [],
   "source": [
    "#some news containes only links or tags thus after preprocessing they became empty text. We remove those because they are irrelevant for our analysis\n",
    "df_True_text= df_True_text[ ~df_True_text['text'].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlk4FpJpXx0w"
   },
   "outputs": [],
   "source": [
    "print(\"shape of the True news dataframe after preprocessing: \", df_True_text.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aF5rqcq4Ng9i"
   },
   "outputs": [],
   "source": [
    "#save the new dataframe\n",
    "df_True_text.to_csv(os.path.join(FEATURES_FOLDER,\"df_True_text.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVOMposUKxCQ"
   },
   "source": [
    "### Sentiment analysis with coreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present the code to run on a local computer, if you want to run it on google colab which is better and advised see the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** to run the coreNLP analysis on your local computer, you need first to download the the stanford coreNLP file from https://stanfordnlp.github.io/CoreNLP/download.html, then you need to open a java pipeline on another jupyter notebook as follows:   \n",
    "cd stanford-corenlp-full-2018-10-05  \n",
    "!java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3I7dcW8KxCQ",
    "outputId": "21c417df-ddc7-4fc6-fafb-d422c37cae66"
   },
   "outputs": [],
   "source": [
    "!pip3 install pycorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tH6ebok-KxCQ",
    "outputId": "d72ed6b7-d857-4e26-c79f-792cefd597e5"
   },
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "#here we connect the coreNLP to the java pipline that we open on the corresponding port number\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PcRPp6tKxCQ"
   },
   "outputs": [],
   "source": [
    "def stanford_sentiment(text_str, show=False):\n",
    "    \n",
    "    res = nlp.annotate(text_str,\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 400000,\n",
    "                   })\n",
    "    #print(res)\n",
    "    \n",
    "    #get parses \n",
    "    parses = []\n",
    "    for elem in res['sentences']:\n",
    "        parses.append(elem['parse'])\n",
    "        \n",
    "    numSentence = len(res[\"sentences\"])\n",
    "    numWords = len(text_str.split())\n",
    "    \n",
    "    # data arrangement\n",
    "    arraySentVal = np.zeros(numSentence)\n",
    "\n",
    "    for i, s in enumerate(res[\"sentences\"]):\n",
    "        arraySentVal[i] = int(s[\"sentimentValue\"])\n",
    "\n",
    "    # sum of sentiment values \n",
    "    totSentiment = sum(arraySentVal)\n",
    "\n",
    "    # avg. of sentiment values \n",
    "    avgSentiment = np.mean(arraySentVal)\n",
    "\n",
    "    # frequency of sentimentValue\n",
    "    bins = [0,1,2,3,4,5,6]\n",
    "    freq = np.histogram(arraySentVal, bins)[0]    # getting freq. only w/o bins\n",
    "    \n",
    "    #shows the computes values if requested, used to test the method\n",
    "    if(show):\n",
    "        for s in res[\"sentences\"]:\n",
    "            print(\"%d: '%s': %s %s\" % (\n",
    "                s[\"index\"],\n",
    "                \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "                s[\"sentimentValue\"], s[\"sentiment\"]))\n",
    "\n",
    "    return(numSentence, numWords, totSentiment, avgSentiment, freq, parses )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ6o0wrkKxCQ"
   },
   "source": [
    "#### Fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9j_MmVvKxCQ",
    "outputId": "f493d932-5ea5-4c37-f551-f1ac9896c32f"
   },
   "outputs": [],
   "source": [
    "df_Fake_text['text'].iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDyvEi9HKxCR",
    "outputId": "15ba3665-cd4b-4f34-ce9b-bf10760c4ee2"
   },
   "outputs": [],
   "source": [
    "#takes a lot of time\n",
    "df_Fake_text['sentiment']= df_Fake_text['text'].apply(stanford_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XgO02PRKxCR"
   },
   "outputs": [],
   "source": [
    "#numSentence, numWords, totSentiment, avgSentiment, freq, parses\n",
    "df_Fake_text[['numSentence', 'numWords', 'totSentiment', 'avgSentiment', 'positive_Sentiment', 'negative_Sentiment',\n",
    "              'neutral_Sentiment', 'parses']]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdVakGFoKxCR",
    "outputId": "9fd2d990-d5ac-47e3-bc95-f44ba90bdf37"
   },
   "outputs": [],
   "source": [
    "df_Fake_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRNCC37uKxCR",
    "outputId": "1f14e35a-124a-4ed1-93f7-5858f00c50cb"
   },
   "outputs": [],
   "source": [
    "#\"Very negative\" = 0 \"Negative\" = 1 \"Neutral\" = 2 \"Positive\" = 3 \"Very positive\" = 4\n",
    "\n",
    "#in our case we need to map very positive to positive and very neg to  neg\n",
    "\n",
    "for i in range( len( df_Fake_text)):\n",
    "    #print(i)\n",
    "    elem= stanford_sentiment(df_Fake_text['text'].iloc[i])\n",
    "    freq= elem[4]\n",
    "    df_Fake_text.iloc[i, 1:]= [elem[0], elem[1], elem[2],elem[3], freq[3]+freq[4] ,freq[0]+freq[1] , freq[2], elem[5]]\n",
    "    if( i%10 ==0):\n",
    "        #print(\"let's save\")\n",
    "        df_Fake_text.to_csv(os.path.join(FEATURES_FOLDER,'df_Fake_text.csv'), index=False)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMwjFPQEKxCS"
   },
   "source": [
    "#### True news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrJ7E_grKxCS"
   },
   "outputs": [],
   "source": [
    "#numSentence, numWords, totSentiment, avgSentiment, freq, parses\n",
    "df_True_text[['numSentence', 'numWords', 'totSentiment', 'avgSentiment', 'positive_Sentiment', 'negative_Sentiment',\n",
    "              'neutral_Sentiment', 'parses']]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rX6yj21sKxCS",
    "outputId": "8568d18a-d79f-4b61-e97e-4c6d1ff6bdad"
   },
   "outputs": [],
   "source": [
    "df_True_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6-YNOUZKxCS"
   },
   "outputs": [],
   "source": [
    "#\"Very negative\" = 0 \"Negative\" = 1 \"Neutral\" = 2 \"Positive\" = 3 \"Very positive\" = 4\n",
    "\n",
    "#in our case we need to map very positive to positive and very neg to  neg\n",
    "\n",
    "for i in range( len( df_True_text)):\n",
    "    #print(i)\n",
    "    elem= stanford_sentiment(df_True_text['text'].iloc[i])\n",
    "    freq= elem[4]\n",
    "    df_True_text.iloc[i, 1:]= [elem[0], elem[1], elem[2],elem[3], freq[3]+freq[4] ,freq[0]+freq[1] , freq[2], elem[5]]\n",
    "    if( i%10 ==0):\n",
    "        #print(\"let's save\")\n",
    "        df_True_text.to_csv(os.path.join(FEATURES_FOLDER,'df_True_text.csv'), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uBogZbkMMpx"
   },
   "source": [
    "### Sentiment analysis with coreNLP on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDnd_92TPlL9"
   },
   "source": [
    "In this part we try to perform the same sentiment analysis as the authors did in their word on the diplomacy game. We use the coreNLP of Stanford to quantifie the negative, positive and neutral sentiments in each sentence in the news and take the average for each news.\n",
    "These computations are very time and bandwidth consuming thus we run them on google Colab. But we weren't able to run them on the entire dataset which is quite big. We performed the computations on the first 3000 entries of the dataset for the True and Fake news respectively to be able to compare them. Since the entries of the datasets are independent we consider than 3000 samples can be enough to describe on average their trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oerr_ERnUBbg"
   },
   "source": [
    "Rq: The tutorial on how to run the Stanford coreNLP on google Colab can be found in this link : https://colab.research.google.com/github/stanfordnlp/stanza/blob/master/demo/Stanza_CoreNLP_Interface.ipynb#scrollTo=mbOBugvd9JaM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puAV6sI0MTSG",
    "outputId": "84d61565-c35a-4ec0-b29b-2d560416f14f"
   },
   "outputs": [],
   "source": [
    "# Install stanza; note that the prefix \"!\" is not needed if you are running in a terminal\n",
    "!pip install stanza\n",
    "\n",
    "# Import stanza\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Hc2Dy0dMXHz",
    "outputId": "edb7aec3-8143-4d84-86b1-cd2b9e7f91df"
   },
   "outputs": [],
   "source": [
    "# Download the Stanford CoreNLP package with Stanza's installation command\n",
    "# This'll take several minutes, depending on the network speed\n",
    "corenlp_dir = './corenlp'\n",
    "stanza.install_corenlp(dir=corenlp_dir)\n",
    "\n",
    "# Set the CORENLP_HOME environment variable to point to the installation location\n",
    "import os\n",
    "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6YwqB-iMdtq",
    "outputId": "a51e6740-8ff7-465d-8ecc-f5c8e568de8e"
   },
   "outputs": [],
   "source": [
    "# Examine the CoreNLP installation folder to make sure the installation is successful\n",
    "!ls $CORENLP_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RayU70G_MhO8"
   },
   "outputs": [],
   "source": [
    "# Import client module\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mhz2dO4OM45g",
    "outputId": "e3b304fc-dd0b-499c-df28-e5c03bced336"
   },
   "outputs": [],
   "source": [
    "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
    "client = CoreNLPClient(\n",
    "    annotators=['sentiment'], \n",
    "    outputFormat= 'json',\n",
    "    memory='16G', \n",
    "    endpoint='http://localhost:9002',\n",
    "    be_quiet=True)\n",
    "print(client)\n",
    "\n",
    "# Start the background server and wait for some time\n",
    "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
    "client.start()\n",
    "import time; time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPXV_2KdNOfg",
    "outputId": "160062ec-30bb-4d34-f626-4b487e66ed5a"
   },
   "outputs": [],
   "source": [
    "# Print background processes and look for java\n",
    "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
    "!ps -o pid,cmd | grep java\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrSrSaShLvcU"
   },
   "outputs": [],
   "source": [
    "#used to kill a pipeline if needed\n",
    "#!kill 908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKMV9z30NO_y"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function that uses the Stanford coreNLP to annotate the sentences of a given text entry and return:\n",
    "-number of sentences in the given text \n",
    "-number of words in the given text\n",
    "-total number of sentiments \n",
    "-average number of snetiments per sentence \n",
    "-frequency of each sentiment (negative, positive and neutral)\n",
    "-parses for each sentence\n",
    "\"\"\"\n",
    "def stanford_sentiment(text_str, show=False):\n",
    "    \n",
    "    res =  client.annotate(text_str,\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 400000,\n",
    "                   })\n",
    "    \n",
    "    \n",
    "    #get parses \n",
    "    parses = []\n",
    "    for elem in res['sentences']:\n",
    "        parses.append(elem['parse'])\n",
    "\n",
    "    #nb of sentences and words    \n",
    "    numSentence = len(res[\"sentences\"])\n",
    "    numWords = len(text_str.split())\n",
    "    \n",
    "    # data arrangement\n",
    "    arraySentVal = np.zeros(numSentence)\n",
    "\n",
    "    for i, s in enumerate(res[\"sentences\"]):\n",
    "        arraySentVal[i] = int(s[\"sentimentValue\"])\n",
    "\n",
    "    # sum of sentiment values \n",
    "    totSentiment = sum(arraySentVal)\n",
    "\n",
    "    # avg. of sentiment values \n",
    "    avgSentiment = np.mean(arraySentVal)\n",
    "\n",
    "    # frequency of sentimentValue\n",
    "    bins = [0,1,2,3,4,5,6]\n",
    "    freq = np.histogram(arraySentVal, bins)[0]    # getting freq. only w/o bins\n",
    "    if(show):\n",
    "        for s in res[\"sentences\"]:\n",
    "            print(\"%d: '%s': %s %s\" % (\n",
    "                s[\"index\"],\n",
    "                \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "                s[\"sentimentValue\"], s[\"sentiment\"]))\n",
    "\n",
    "    return(numSentence, numWords, totSentiment, avgSentiment, freq, parses )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFGMnBcbN5Fg"
   },
   "outputs": [],
   "source": [
    "#Use GPU if available\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "                torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QCkOi5lN0C9"
   },
   "source": [
    "#### Fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BinjxOPcNfD9"
   },
   "outputs": [],
   "source": [
    "#add empty columns in the Fake dataframe for numSentence, numWords, totSentiment, avgSentiment, freq andparses\n",
    "df_Fake_text[['numSentence', 'numWords', 'totSentiment', 'avgSentiment', 'positive_Sentiment', 'negative_Sentiment',\n",
    "              'neutral_Sentiment', 'parses']]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "65oKzlI1NiMm",
    "outputId": "86afec30-a0f8-45ab-8d08-7bee676cbda4"
   },
   "outputs": [],
   "source": [
    "df_Fake_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5PNaTAoPKnF"
   },
   "source": [
    "Some entries caused a read timeout and we are unable to process them, those entries were deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "FMSi61G6NiP5",
    "outputId": "8163fdb0-57e2-450c-9332-61c11090d965"
   },
   "outputs": [],
   "source": [
    "#The returned frequencies are orderes as follows: \"Very negative\" = 0 \"Negative\" = 1 \"Neutral\" = 2 \"Positive\" = 3 \"Very positive\" = 4\n",
    "#In our case we need to map \" Very Positive\" to \"Positive\" and \"Very Negative\" to  \"Negative\" to match the work of the authors on the diplomacy game\n",
    "\n",
    "\n",
    "#We run the stanford_sentiment method on each Fake news and store the returned values in the dataframe \n",
    "#we save the dataframe evry 10 iterations to make sure not a lot of data is lost in case of a runtime stop\n",
    "for i in range( len( df_Fake_text)):\n",
    "    #print(i)\n",
    "    elem= stanford_sentiment(df_Fake_text['text'].iloc[i])\n",
    "    freq= elem[4]\n",
    "    df_Fake_text.iloc[i, 1:]= [elem[0], elem[1], elem[2],elem[3], freq[3]+freq[4] ,freq[0]+freq[1] , freq[2], elem[5]]\n",
    "    if( i%10 ==0):\n",
    "        #print(\"let's save\")\n",
    "        df_Fake_text.to_csv(os.path.join(FEATURES_FOLDER,'df_Fake_text.csv'), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM4zugcSN71G"
   },
   "source": [
    "#### True news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mPu3XwDN7FM"
   },
   "outputs": [],
   "source": [
    "# add empty columns in the True dataframe for numSentence, numWords, totSentiment, avgSentiment, freq andparses\n",
    "df_True_text[['numSentence', 'numWords', 'totSentiment', 'avgSentiment', 'positive_Sentiment', 'negative_Sentiment',\n",
    "              'neutral_Sentiment', 'parses']]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoQWX-YuOBer"
   },
   "outputs": [],
   "source": [
    "df_True_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaVQ5nzyQ3TS"
   },
   "source": [
    "Some entries caused a read timeout and we are unable to process them, those entries were deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drwC_mb1ODTU"
   },
   "outputs": [],
   "source": [
    "#The returned frequencies are orderes as follows: \"Very negative\" = 0 \"Negative\" = 1 \"Neutral\" = 2 \"Positive\" = 3 \"Very positive\" = 4\n",
    "#In our case we need to map \" Very Positive\" to \"Positive\" and \"Very Negative\" to  \"Negative\" to match the work of the authors on the diplomacy game\n",
    "\n",
    "\n",
    "#We run the stanford_sentiment method on each True news and store the returned values in the dataframe \n",
    "#we save the dataframe evry 10 iterations to make sure not a lot of data is lost in case of a runtime stop\n",
    "for i in range( 1398, len( df_True_text)):\n",
    "    #print(i)\n",
    "    elem= stanford_sentiment(df_True_text['text'].iloc[i])\n",
    "    freq= elem[4]\n",
    "    df_True_text.iloc[i, 1:]= [elem[0], elem[1], elem[2],elem[3], freq[3]+freq[4] ,freq[0]+freq[1] , freq[2], elem[5]]\n",
    "    if( i%10 ==0):\n",
    "        #print(\"let's save\")\n",
    "        df_True_text.to_csv(os.path.join(FEATURES_FOLDER,'df_True_text.csv'), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5v8DWD4NiS2",
    "outputId": "bc2c1133-95a5-423f-e174-5ce3525f32ee"
   },
   "outputs": [],
   "source": [
    "# Shut down the background CoreNLP server\n",
    "client.stop()\n",
    "\n",
    "time.sleep(10)\n",
    "!ps -o pid,cmd | grep java"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qVOMposUKxCQ"
   ],
   "name": "preprocess_coreNLP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
